    1  ls
    2  cd build
    3  ls
    4  rm -rf flash-attention/
    5  ls
    6  export MAX_JOBS=8
    7  export CMAKE_BUILD_PARALLEL_LEVEL=8
    8  git clone https://github.com/Dao-AILab/flash-attention.git --recursive
    9  ls
   10  cd flash-attention/
   11  ls
   12  MAX_JOBS=8 pip wheel flash-attn --no-build-isolation -w dist/
   13  ls
   14  cd flash_attn/
   15  ls
   16  cd ..
   17  ls
   18  cd ..
   19  ls
   20  rm -rf flash-attention/
   21  ls
   22  git clone https://github.com/Dao-AILab/flash-attention.git --recursive
   23  ls
   24  cd flash
   25  cd flash-attention/
   26  ls
   27  pip wheel . --no-build-isolation -w dist/
   28  cd ..
   29  ls
   30  rm flash-attention/
   31  rm -rf flash-attention/
   32  git clone https://github.com/Dao-AILab/flash-attention.git --recursive
   33  ls
   34  cd flash-attention/
   35  ls
   36  rm -rf build/ dist/ *.egg-info
   37  pip install build wheel
   38  python -m build --wheel
   39  pip install build
   40  python -m build --wheel --no-isolation
   41  pip install dist/flash_attn-2.8.3-*.whl
   42  cd ..
   43  ls
   44  cd build
   45  python test_flash.py
   46  git clone https://github.com/thu-ml/SageAttention.git
   47  ls
   48  cd SageAttention/
   49  ls
   50  rm -rf build/ dist/ *.egg-info
   51  ls
   52  python -m build --wheel --no-isolation
   53  export MAX_JOBS=16
   54  export CMAKE_BUILD_PARALLEL_LEVEL=16
   55  python -m build --wheel --no-isolation
   56  cd ..
   57  sl 
   58  cd ..
   59  ls
   60  cd build/
   61  ls
   62  rm -rf SageAttention/
   63  git clone https://github.com/thu-ml/SageAttention.git
   64  cd SageAttention/
   65  MAX_JOBS=16 python -m build --wheel --no-isolation
   66  pip install dist/sageattention-2.2.0-cp311-cp311-linux_x86_64.whl
   67  cd ..
   68  python test_flash.py
   69  python test_sage.py 
   70  cd ..
   71  history >output/history.txt
